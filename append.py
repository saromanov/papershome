from django.utils import timezone
from home.models import Paper, CodeLink, AdditionalLinks


def population():
    p = Paper(title='Segmental Recurrent Neural Networks', description='We introduce segmental recurrent neural networks(SRNNs) which define, given an input sequence, a joint probability distribution over segmentations of the input and labelings of the segments. Representations of the input segments(i.e., contiguous subsequences of the input) are computed by encoding their constituent tokens using bidirectional recurrent neural nets, and these "segment embeddings" are used to define compatibility scores with output labels. These local compatibility scores are integrated using a global semi - Markov conditional random field. Both fully supervised training - - in which segment boundaries and labels are observed - - as well as partially supervised training - - in which segment boundaries are latent - - are straightforward. Experiments on handwriting recognition and joint Chinese word segmentation / POS tagging show that, compared to models that do not explicitly represent segments such as BIO tagging schemes and connectionist temporal classification(CTC), SRNNs obtain substantially higher accuracies.', pubdate=timezone.now(),
            author='Lingpeng Kong, Chris Dyer, Noah A. Smith', version='1', link='http://arxiv.org/abs/1511.06018')
    # p.tags.add('RNN', 'BRNN')
    code = CodeLink(title='Github link to implementation of SRNN', repolink='https://github.com/fchollet/keras', usage='import keras')
    code.save()
    p.repo = code
    addlinks = AdditionalLinks()
    links = {'http://www.sighan.org/bakeoff2005/': 'Second International Chinese Word Segmentation Bakeoff'}
    addlinks.set(links)
    addlinks.save()
    p.links = addlinks
    p.save()

    p = Paper(title='Variable Rate Image Compression with Recurrent Neural Networks', description='Although image compression has been actively studied for decades, there has been relatively little research on learning to compress images with modern neural networks. Standard approaches, such as those employing patch - based autoencoders, have shown a great deal of promise but cannot compete with popular image codecs because they fail to address three questions: 1) how to effectively binarize activations: in the absence of binarization, a bottleneck layer alone tends not to lead to efficient compression; 2) how to achieve variable - rate encoding: a standard autoencoder generates a fixed - length code for each fixed - resolution input patch, resulting in the same cost for low - and high - entropy patches, and requiring the network to be completely retrained to achieve different compression rates; and 3) how to avoid block artifacts: patch - based approaches are prone to block discontinuities. We propose a general framework for variable - rate image compression and a novel architecture based on convolutional and deconvolutional recurrent networks, including LSTMs, that address these issues and report promising results compared to existing baseline codecs. We evaluate the proposed methods on a large - scale benchmark consisting of tiny images(32×32), which proves to be very challenging for all the methods. ', breif_description=' Although image compression has been actively studied for decades, there has been relatively little research on learning to compress images with modern neural networks', pubdate=timezone.now(), author="George Toderici, Sean M. O'Malley, Sung Jin Hwang, Damien Vincent, David Minnen, Shumeet Baluja, Michele Covell, Rahul Sukthankar", version='2', link='http://arxiv.org/pdf/1511.06085v2.pdf')
    code = CodeLink(title='Github link to implementation of this model')
    code.save()
    p.code = code
    p.save()

    p = Paper(title='Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks', description='In this paper we present a method for learning a discriminative classifier from unlabeled or partially labeled data. Our approach is based on an objective function that trades-off mutual information between observed examples and their predicted categorical class distribution, against robustness of the classifier to an adversarial generative model. The resulting algorithm can either be interpreted as a natural generalization of the generative adversarial networks (GAN) framework or as an extension of the regularized information maximization (RIM) framework to robust classification against an optimal adversary. We empirically evaluate our method - which we dub categorical generative adversarial networks (or CatGAN) - on synthetic data as well as on challenging image classification tasks, demonstrating the robustness of the learned classifiers. We further qualitatively assess the fidelity of samples generated by the adversarial generator that is learned alongside the discriminative classifier, and identify links between the CatGAN objective and discriminative clustering algorithms (such as RIM).', breif_description='In this paper we present a method for learning a discriminative classifier from unlabeled or partially labeled data', pubdate=timezone.now(), author='Jost Tobias Springenberg', version='1',
    link='http://arxiv.org/pdf/1511.06390v1.pdf')
    p.save()

    p = Paper(title="Training Deep Networks on Spark', description='Training deep networks is a time-consuming process, with networks for object recognition often requiring multiple days to train. For this reason, leveraging the resources of a cluster to speed up training is an important area of work. However, widely-popular batch-processing computational frameworks like MapReduce and Spark were not designed to support the asynchronous and communication-intensive workloads of existing distributed deep learning systems. We introduce SparkNet, a framework for training deep networks in Spark. Our implementation includes a convenient interface for reading data from Spark RDDs, a Scala interface to the Caffe deep learning framework, and a lightweight multi-dimensional tensor library. Using a simple parallelization scheme for stochastic gradient descent, SparkNet scales well with the cluster size and tolerates very high-latency communication. Furthermore, it is easy to deploy and use with no parameter tuning, and it is compatible with existing Caffe models. We quantify the dependence of the speedup obtained by SparkNet on the number of machines, the communication frequency, and the cluster's communication overhead, and we benchmark our system's performance on the ImageNet dataset. The code for SparkNet is available at this https URL", breif_description='Training deep networks is a time-consuming process, with networks for object recognition often requiring multiple days to train. For this reason, leveraging the resources of a cluster to speed up training is an important area of work.', pubdate=timezone.now(),author='François Garillot', version='1', link='http://arxiv.org/abs/1511.06051')
    code = CodeLink(title='SparkNet Distributed Neural Networks for Spark. Details are available in the paper.', repolink='https://github.com/amplab/SparkNet',usage='val netParam = NetParam ("LeNet", RDDLayer("data", shape=List(batchsize, 1, 28, 28), None), RDDLayer("label", shape=List(batchsize, 1), None), ConvolutionLayer("conv1", List("data"), kernel=(5,5), numOutput=20), PoolingLayer("pool1", List("conv1"), pooling=Pooling.Max, kernel=(2,2), stride=(2,2)), ConvolutionLayer("conv2", List("pool1"), kernel=(5,5), numOutput=50), PoolingLayer("pool2", List("conv2"), pooling=Pooling.Max, kernel=(2,2), stride=(2,2)), InnerProductLayer("ip1", List("pool2"), numOutput=500), ReLULayer("relu1", List("ip1")), InnerProductLayer("ip2", List("relu1"), numOutput=10), SoftmaxWithLoss("loss", List("ip2", "label")) )')
    code.save()
    p.repo = code
    addlinks = AdditionalLinks()
    addlinks.set({'homepage': 'https://amplab.cs.berkeley.edu/publication/sparknet-training-deep-networks-on-spark/'})
    addlinks.save()
    p.links = addlinks
    p.save()



if __name__ == '__main__':
    print("Population script")
    population()

