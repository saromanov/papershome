from django.utils import timezone
from home.models import Paper


def population():
    p = Paper(title='Segmental Recurrent Neural Networks', description='We introduce segmental recurrent neural networks(SRNNs) which define, given an input sequence, a joint probability distribution over segmentations of the input and labelings of the segments. Representations of the input segments(i.e., contiguous subsequences of the input) are computed by encoding their constituent tokens using bidirectional recurrent neural nets, and these "segment embeddings" are used to define compatibility scores with output labels. These local compatibility scores are integrated using a global semi - Markov conditional random field. Both fully supervised training - - in which segment boundaries and labels are observed - - as well as partially supervised training - - in which segment boundaries are latent - - are straightforward. Experiments on handwriting recognition and joint Chinese word segmentation / POS tagging show that, compared to models that do not explicitly represent segments such as BIO tagging schemes and connectionist temporal classification(CTC), SRNNs obtain substantially higher accuracies.', pubdate=timezone.now(),
            author='Lingpeng Kong, Chris Dyer, Noah A. Smith', version='1', link='http://arxiv.org/abs/1511.06018')
    # p.tags.add('RNN', 'BRNN')
    p.save()

    p = Paper(title='Variable Rate Image Compression with Recurrent Neural Networks', description='Although image compression has been actively studied for decades, there has been relatively little research on learning to compress images with modern neural networks. Standard approaches, such as those employing patch - based autoencoders, have shown a great deal of promise but cannot compete with popular image codecs because they fail to address three questions: 1) how to effectively binarize activations: in the absence of binarization, a bottleneck layer alone tends not to lead to efficient compression; 2) how to achieve variable - rate encoding: a standard autoencoder generates a fixed - length code for each fixed - resolution input patch, resulting in the same cost for low - and high - entropy patches, and requiring the network to be completely retrained to achieve different compression rates; and 3) how to avoid block artifacts: patch - based approaches are prone to block discontinuities. We propose a general framework for variable - rate image compression and a novel architecture based on convolutional and deconvolutional recurrent networks, including LSTMs, that address these issues and report promising results compared to existing baseline codecs. We evaluate the proposed methods on a large - scale benchmark consisting of tiny images(32Ã—32), which proves to be very challenging for all the methods. ', breif_description=' Although image compression has been actively studied for decades, there has been relatively little research on learning to compress images with modern neural networks', pubdate=timezone.now(), author="George Toderici, Sean M. O'Malley, Sung Jin Hwang, Damien Vincent, David Minnen, Shumeet Baluja, Michele Covell, Rahul Sukthankar", version='2', link='http://arxiv.org/pdf/1511.06085v2.pdf')
    p.save()

    p = Paper(title='Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks', description='In this paper we present a method for learning a discriminative classifier from unlabeled or partially labeled data. Our approach is based on an objective function that trades-off mutual information between observed examples and their predicted categorical class distribution, against robustness of the classifier to an adversarial generative model. The resulting algorithm can either be interpreted as a natural generalization of the generative adversarial networks (GAN) framework or as an extension of the regularized information maximization (RIM) framework to robust classification against an optimal adversary. We empirically evaluate our method - which we dub categorical generative adversarial networks (or CatGAN) - on synthetic data as well as on challenging image classification tasks, demonstrating the robustness of the learned classifiers. We further qualitatively assess the fidelity of samples generated by the adversarial generator that is learned alongside the discriminative classifier, and identify links between the CatGAN objective and discriminative clustering algorithms (such as RIM).', breif_description='In this paper we present a method for learning a discriminative classifier from unlabeled or partially labeled data', pubdate=timezone.now(), author='Jost Tobias Springenberg', version='1',
    link='http://arxiv.org/pdf/1511.06390v1.pdf')
    p.save()



if __name__ == '__main__':
    print("Population script")
    population()

